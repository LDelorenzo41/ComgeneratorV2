// supabase/functions/rag-chat/index.ts
// VERSION "MULTI-DOMAINES" (V1 Intelligence + V2 S√©curit√© + Architecture G√©n√©rique)
// + Support switches corpus (perso/ProfAssist/IA)
// + Support filtres m√©tadonn√©es (Niveaux/Mati√®res/Types)

import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';

declare const Deno: {
  env: {
    get(key: string): string | undefined;
  };
  serve(handler: (req: Request) => Promise<Response>): void;
};

// ============================================================================
// 1. CONFIGURATION DES DOMAINES M√âTIER (Le C≈ìur du Syst√®me)
// ============================================================================

interface DomainConfig {
  id: string;
  name: string;
  keywords: RegExp[];
  docPatterns: string[];
  bonus: number;
  minDocs: number;
  promptRole: string;
}

const DOMAINS: Record<string, DomainConfig> = {
  LANGUES: {
    id: 'LANGUES',
    name: 'Langues Vivantes / CECR',
    keywords: [
      /\bcecr\b/i, /\bniveau\s*de\s*langue/i, /\b[a-c][1-2]\b/i, 
      /\bcomp√©tence\s*linguistique/i, /\blangue\s*vivante/i, /\blv[1-2]\b/i,
      /\boral\s*(compr√©hension|production)/i, /\b√©crit\s*(compr√©hension|production)/i
    ],
    docPatterns: ['cecr', 'cecrl', 'cadre europ√©en', 'guide-langue', 'reperles'],
    bonus: 0.25,
    minDocs: 3,
    promptRole: "Expert en didactique des langues et CECR"
  },
  EPS: {
    id: 'EPS',
    name: '√âducation Physique et Sportive',
    keywords: [
      /\beps\b/i, /\b√©ducation\s*physique/i, /\bchamp\s*d'apprentissage/i, 
      /\bapsa\b/i, /\bmotricit√©/i, /\bperformance\s*sportive/i, /\bsport\b/i
    ],
    docPatterns: ['eps', '√©ducation physique', 'sport', 'apsa', 'guide-eps'],
    bonus: 0.20,
    minDocs: 2,
    promptRole: "Expert en p√©dagogie de l'EPS et motricit√©"
  },
  SCIENCES: {
    id: 'SCIENCES',
    name: 'Math√©matiques et Sciences',
    keywords: [
      /\bmath[s]?\b/i, /\bmath√©matique/i, /\bg√©om√©trie/i, /\balg√®bre/i, 
      /\bth√©or√®me/i, /\bcalcul\b/i, /\bphysique\b/i, /\bchimie\b/i, /\bsvt\b/i
    ],
    docPatterns: ['math', 'science', 'physique', 'chimie'],
    bonus: 0.15,
    minDocs: 2,
    promptRole: "Expert en didactique des sciences"
  },
  HUMANITES: {
    id: 'HUMANITES',
    name: 'Histoire-G√©o et Fran√ßais',
    keywords: [
      /\bhistoire\b/i, /\bg√©ographie\b/i, /\bemc\b/i, /\bfran√ßais\b/i, 
      /\blitt√©rature/i, /\bgrammaire/i, /\bchronologie/i
    ],
    docPatterns: ['histoire', 'g√©ographie', 'fran√ßais', 'litt√©rature'],
    bonus: 0.15,
    minDocs: 2,
    promptRole: "Expert en humanit√©s et culture g√©n√©rale"
  }
};

const CONFIG = {
  defaultTopK: 8,
  maxTopK: 15,
  similarityThreshold: 0.28,
  referenceDocBonus: 0.10,
  chatModel: 'gpt-4o-mini',
  embeddingModel: 'text-embedding-3-large',
  embeddingDimensions: 1536,
  queryRewritingModel: 'gpt-4o-mini',
  hydeModel: 'gpt-4o-mini',
  rerankingModel: 'gpt-4o-mini',
  rerankingChunkCount: 25,
  rerankingContextLength: 1000,
  finalChunkCount: 10,
  maxHistoryMessages: 10,
  excerptLength: 450,
};

// ============================================================================
// TYPES
// ============================================================================

type ChatMode = 'corpus_only' | 'corpus_plus_ai';
type SearchMode = 'fast' | 'precise';

interface ChatRequest {
  message: string;
  mode: ChatMode;
  searchMode?: SearchMode;
  conversationId?: string;
  documentId?: string;
  topK?: number;
  // üÜï Nouveaux param√®tres pour la s√©lection des corpus
  usePersonalCorpus?: boolean;
  useProfAssistCorpus?: boolean;
  useAI?: boolean;
  
  // üÜï Filtres documentaires (OPTIONNELS)
  levels?: string[];
  subjects?: string[];
  documentTypes?: string[];
}

interface DocumentInfo {
  id: string;
  title: string;
  scope: string;
}

interface MatchedChunk {
  id: string;
  documentId: string;
  documentTitle: string;
  chunkIndex: number;
  content: string;
  score: number;
  scope?: 'global' | 'user';
  rerankScore?: number;
  llmRawScore?: number;
}

interface SourceChunk {
  documentId: string;
  documentTitle: string;
  chunkId: string;
  chunkIndex: number;
  excerpt: string;
  score: number;
  scope?: 'global' | 'user';
}

// ============================================================================
// HELPERS - CORS & AUTH
// ============================================================================

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

async function createSupabaseClient(authHeader: string) {
  return createClient(Deno.env.get('SUPABASE_URL')!, Deno.env.get('SUPABASE_ANON_KEY')!, {
    global: { headers: { Authorization: authHeader } },
  });
}

async function createServiceClient() {
  return createClient(Deno.env.get('SUPABASE_URL')!, Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!);
}

// ============================================================================
// INTELLIGENCE M√âTIER & D√âTECTION
// ============================================================================

function detectDomainIntent(query: string): DomainConfig | null {
  for (const domain of Object.values(DOMAINS)) {
    if (domain.keywords.some(regex => regex.test(query))) {
      console.log(`[rag-chat] Domain detected: ${domain.id}`);
      return domain;
    }
  }
  return null;
}

function isDomainDocument(docTitle: string, domain: DomainConfig): boolean {
  const titleLower = docTitle.toLowerCase();
  return domain.docPatterns.some(p => titleLower.includes(p));
}

function isReferenceDocument(title: string): boolean {
  return /programme|guide|r√©f√©rentiel|officiel|accompagnement/i.test(title.toLowerCase());
}

function isComparativeQuestion(query: string): boolean {
  const comparativePatterns = [
    /diff[√©e]ren/i, /compar/i, /entre.+et/i, /versus|vs/i, /par rapport/i,
    /contrairement/i, /similitude/i, /commun/i, /cycle\s*\d.+cycle\s*\d/i,
    /niveau\s*[A-C][1-2].+niveau\s*[A-C][1-2]/i,
  ];
  return comparativePatterns.some(p => p.test(query));
}

function extractComparisonTargets(query: string): string[] {
  const targets: string[] = [];
  const cycleMatches = query.match(/cycle\s*(\d)/gi);
  if (cycleMatches) {
    const seenNums = new Set<string>();
    cycleMatches.forEach(m => {
      const num = m.match(/\d/)?.[0];
      if (num && !seenNums.has(num)) { seenNums.add(num); targets.push(`cycle_${num}`); }
    });
  }
  const cecrMatches = query.match(/\b[A-Ca-c][1-2]\b/gi);
  if (cecrMatches) {
    const seen = new Set<string>();
    cecrMatches.forEach(m => {
      const l = m.toUpperCase();
      if (!seen.has(l)) { seen.add(l); targets.push(`cecr_${l}`); }
    });
  }
  return targets;
}

function extractCECRLevels(query: string): string[] {
  const matches = query.match(/\b[A-Ca-c][1-2]\b/gi);
  return matches ? [...new Set(matches.map(m => m.toUpperCase()))] : [];
}

// ============================================================================
// HyDE: HYPOTHETICAL DOCUMENT EMBEDDINGS
// ============================================================================

async function generateHypotheticalAnswer(
  query: string,
  domain: DomainConfig | null,
  apiKey: string
): Promise<{ hypotheticalAnswer: string; tokensUsed: number }> {
  const isComparative = isComparativeQuestion(query);
  const targets = extractComparisonTargets(query);

  let prompt: string;
  
  if (domain?.id === 'LANGUES') {
    const levels = extractCECRLevels(query).join(', ') || 'les niveaux';
    prompt = `Tu es un ${domain.promptRole}. G√©n√®re une r√©ponse technique sur "${query}".
    IMPORTANT (${levels}):
    - Utilise vocabulaire CECR: descripteurs, production/r√©ception.
    - D√©cris ce que l'√©l√®ve "peut faire".
    - 200-400 mots.`;
  } else if (domain?.id === 'EPS') {
    prompt = `Tu es un ${domain.promptRole}. R√©ponds √† "${query}".
    IMPORTANT:
    - Utilise le vocabulaire officiel (Champs d'Apprentissage, AFC, Attendus).
    - Mentionne les conduites motrices et situations d'apprentissage.
    - 200-400 mots.`;
  } else if (isComparative && targets.length >= 2) {
    prompt = `Expert Programmes Scolaires. Compare explicitement ${targets.map(t => t.replace('_', ' ')).join(' et ')} pour "${query}".
    - Structure par diff√©rences et similitudes.
    - Sp√©cificit√©s de chaque cycle.`;
  } else {
    prompt = `Expert √âducation Nationale. R√©ponds factuellement √† "${query}".
    - Utilise le vocabulaire officiel.
    - Structure claire.`;
  }

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${apiKey}`, 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: CONFIG.hydeModel,
        messages: [{ role: 'system', content: 'Tu es un expert p√©dagogique.' }, { role: 'user', content: prompt }],
        temperature: 0.3, max_tokens: 600,
      }),
    });

    if (!response.ok) return { hypotheticalAnswer: query, tokensUsed: 0 };
    const data = await response.json();
    return { hypotheticalAnswer: data.choices[0]?.message?.content || query, tokensUsed: data.usage?.total_tokens || 0 };
  } catch (error) {
    console.warn('[rag-chat] HyDE error:', error);
    return { hypotheticalAnswer: query, tokensUsed: 0 };
  }
}

// ============================================================================
// QUERY REWRITING
// ============================================================================

async function rewriteQueryForSearch(
  query: string,
  domain: DomainConfig | null,
  apiKey: string
): Promise<{ queries: string[]; tokensUsed: number }> {
  let prompt: string;
  
  if (domain?.id === 'LANGUES') {
    const levels = extractCECRLevels(query).join(', ');
    prompt = `Expert Recherche CECR. Question: "${query}"
    G√©n√®re des mots-cl√©s ciblant:
    1. Termes CECR (descripteurs, comp√©tences)
    2. Niveaux sp√©cifiques (${levels})
    JSON: {"queries": ["q1", "q2", ...]}`;
  } else if (domain?.id === 'EPS') {
    prompt = `Expert Recherche EPS. Question: "${query}"
    G√©n√®re des mots-cl√©s ciblant:
    1. Champs d'apprentissage
    2. Activit√©s physiques (APSA)
    3. Comp√©tences vis√©es
    JSON: {"queries": ["q1", "q2", ...]}`;
  } else {
    prompt = `Expert Recherche √âducation. Reformule: "${query}" pour moteur documentaire.
    Utilise synonymes officiels et niveaux scolaires.
    JSON: {"queries": ["q1", "q2", ...]}`;
  }

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${apiKey}`, 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: CONFIG.queryRewritingModel,
        messages: [{ role: 'system', content: 'JSON only.' }, { role: 'user', content: prompt }],
        temperature: 0.3, max_tokens: 300,
      }),
    });
    if (!response.ok) return { queries: [query], tokensUsed: 0 };
    const data = await response.json();
    const jsonMatch = data.choices[0]?.message?.content.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0]);
      return { queries: [query, ...(parsed.queries || [])].slice(0, 6), tokensUsed: data.usage?.total_tokens || 0 };
    }
    return { queries: [query], tokensUsed: data.usage?.total_tokens || 0 };
  } catch (error) {
    return { queries: [query], tokensUsed: 0 };
  }
}

// ============================================================================
// EXTRACTION TERMES-CL√âS
// ============================================================================

function extractKeyTerms(query: string): string[] {
  const lowerQuery = query.toLowerCase();
  const terms: string[] = [];

  const mappings: Record<string, string[]> = {
    'maternelle': ['cycle 1'], 'cycle 1': ['maternelle'],
    'cycle 2': ['CP', 'CE1', 'CE2'],
    'cycle 3': ['CM1', 'CM2', '6e'], 'cycle 4': ['5e', '4e', '3e'],
    'eps': ['√©ducation physique', 'sport', 'apsa'],
    'sport': ['eps', '√©ducation physique'],
    'a1': ['A1', 'd√©butant'], 'a2': ['A2', '√©l√©mentaire'],
    'b1': ['B1', 'ind√©pendant'], 'b2': ['B2', 'avanc√©'],
    'c1': ['C1', 'autonome'],
    'cecr': ['cadre europ√©en', 'descripteur'],
    'math': ['math√©matiques', 'calcul'], 'g√©om√©trie': ['figure', 'espace'],
  };

  query.split(/[\s,.?!]+/).forEach(w => {
    if (w.length > 3 && !['pour','avec','dans','quel','comment'].includes(w.toLowerCase())) terms.push(w);
  });

  const levelMatch = query.match(/\b([A-Ca-c][1-2])\b/g);
  if (levelMatch) levelMatch.forEach(l => terms.push(l.toUpperCase()));

  for (const [k, v] of Object.entries(mappings)) {
    if (lowerQuery.includes(k)) terms.push(...v);
  }

  return [...new Set(terms)];
}

// ============================================================================
// GESTION DOCUMENTS (AVEC FILTRAGE SWITCHES ET METADONN√âES)
// ============================================================================

async function getAllowedDocuments(
  supabase: any, 
  userId: string, 
  docId?: string,
  usePersonalCorpus: boolean = true,
  useProfAssistCorpus: boolean = true,
  filters?: {
    levels?: string[];
    subjects?: string[];
    documentTypes?: string[];
  }
): Promise<Map<string, DocumentInfo>> {
  const docsMap = new Map<string, DocumentInfo>();
  console.log(`[rag-chat] === SECURITY: Fetching allowed documents ===`);
  console.log(`[rag-chat] Filters: personal=${usePersonalCorpus}, profassist=${useProfAssistCorpus}`);

  const { levels, subjects, documentTypes } = filters || {};

  // Si aucun corpus s√©lectionn√©, retourner vide
  if (!usePersonalCorpus && !useProfAssistCorpus) {
    console.log(`[rag-chat] No corpus selected, returning empty`);
    return docsMap;
  }

  let query = supabase
    .from('rag_documents')
    .select('id, title, scope, user_id, levels, subjects, document_type')
    .eq('status', 'ready');
  
  if (docId) {
    query = query.eq('id', docId);
  } else {
    // Construire le filtre selon les switches
    if (usePersonalCorpus && useProfAssistCorpus) {
      // Les deux corpus
      query = query.or(`scope.eq.global,and(scope.eq.user,user_id.eq.${userId})`);
    } else if (useProfAssistCorpus) {
      // Seulement ProfAssist (global)
      query = query.eq('scope', 'global');
    } else if (usePersonalCorpus) {
      // Seulement personnel
      query = query.eq('scope', 'user').eq('user_id', userId);
    }
  }

  // üÜï Filtrage m√©tier bas√© sur m√©tadonn√©es (si fournies)
  if (levels?.length) {
    query = query.overlaps('levels', levels);
  }

  if (subjects?.length) {
    query = query.overlaps('subjects', subjects);
  }

  if (documentTypes?.length) {
    query = query.in('document_type', documentTypes);
  }

  const { data } = await query;
  if (data) {
    data.forEach((d: any) => docsMap.set(d.id, { id: d.id, title: d.title, scope: d.scope }));
    console.log(`[rag-chat] Allowed docs count: ${data.length}`);
  }
  return docsMap;
}

// ============================================================================
// EMBEDDINGS
// ============================================================================

async function createEmbedding(text: string, apiKey: string): Promise<number[]> {
  try {
    const response = await fetch('https://api.openai.com/v1/embeddings', {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${apiKey}`, 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: CONFIG.embeddingModel,
        input: text.replace(/\n/g, ' '),
        dimensions: CONFIG.embeddingDimensions,
      }),
    });
    if (!response.ok) throw new Error(`Embedding API Error: ${response.statusText}`);
    const data = await response.json();
    return data.data[0].embedding;
  } catch (err) {
    console.error('[rag-chat] Embedding Error:', err);
    throw err;
  }
}

// ============================================================================
// STRAT√âGIES DE RECHERCHE
// ============================================================================

async function searchByVector(supabase: any, userId: string, embedding: number[], topK: number, allowedDocIds: Set<string>): Promise<MatchedChunk[]> {
  try {
    const { data, error } = await supabase.rpc('match_rag_chunks', {
      p_query_embedding: `[${embedding.join(',')}]`,
      p_similarity_threshold: CONFIG.similarityThreshold,
      p_match_count: topK * 3,
      p_user_id: userId,
      p_document_id: null,
    });

    if (error) return [];

    return (data || [])
      .filter((item: any) => allowedDocIds.has(item.document_id))
      .map((item: any) => ({
        id: item.id, documentId: item.document_id, documentTitle: item.document_title,
        chunkIndex: item.chunk_index, content: item.content, score: item.similarity, scope: item.scope,
      }));
  } catch (err) { return []; }
}

async function searchByKeywords(
  supabase: any,
  allowedDocIds: string[],
  allowedDocs: Map<string, DocumentInfo>,
  keywords: string[]
): Promise<MatchedChunk[]> {
  if (keywords.length === 0 || allowedDocIds.length === 0) return [];
  
  const chunkScores = new Map<string, { chunk: MatchedChunk; score: number }>();
  const effectiveKeywords = keywords.slice(0, 5);

  for (const keyword of effectiveKeywords) {
    if (keyword.length < 3) continue;
    const { data: chunks } = await supabase
      .from('rag_chunks')
      .select('id, document_id, chunk_index, content, scope')
      .in('document_id', allowedDocIds)
      .ilike('content', `%${keyword}%`)
      .limit(8);

    if (chunks) {
      for (const chunk of chunks) {
        const doc = allowedDocs.get(chunk.document_id);
        if (!doc) continue;
        
        const key = chunk.id;
        const existing = chunkScores.get(key);
        const titleBonus = doc.title.toLowerCase().includes(keyword.toLowerCase()) ? 0.2 : 0;

        if (existing) {
          existing.score += 0.3 + titleBonus;
        } else {
          chunkScores.set(key, {
            chunk: {
              id: chunk.id, documentId: doc.id, documentTitle: doc.title,
              chunkIndex: chunk.chunk_index, content: chunk.content,
              score: 0.70 + titleBonus, scope: chunk.scope as any || doc.scope,
            },
            score: 0.70 + titleBonus,
          });
        }
      }
    }
  }
  return Array.from(chunkScores.values()).sort((a, b) => b.score - a.score).map(i => i.chunk);
}

async function searchSpecificDomainDocuments(
  supabase: any,
  allowedDocs: Map<string, DocumentInfo>,
  domain: DomainConfig,
  query: string
): Promise<MatchedChunk[]> {
  const targetDocIds: string[] = [];
  
  allowedDocs.forEach((doc, id) => {
    if (isDomainDocument(doc.title, domain)) targetDocIds.push(id);
  });

  if (targetDocIds.length === 0) return [];
  console.log(`[rag-chat] Searching specific ${domain.id} docs (${targetDocIds.length} found)...`);

  const { data: chunks } = await supabase
    .from('rag_chunks')
    .select('id, document_id, chunk_index, content, scope')
    .in('document_id', targetDocIds)
    .limit(30);

  const results: MatchedChunk[] = [];
  
  if (chunks) {
    for (const chunk of chunks) {
      const contentLower = chunk.content.toLowerCase();
      let score = 0.85;

      const queryWords = extractKeyTerms(query);
      let matches = 0;
      queryWords.forEach(w => { if (contentLower.includes(w.toLowerCase())) matches++; });
      
      score += (matches * 0.05);

      if (matches > 0 || domain.id === 'LANGUES') {
         results.push({
           id: chunk.id, documentId: chunk.document_id, documentTitle: allowedDocs.get(chunk.document_id)!.title,
           chunkIndex: chunk.chunk_index, content: chunk.content, score, scope: chunk.scope as any
         });
      }
    }
  }
  return results.sort((a, b) => b.score - a.score).slice(0, 15);
}

// ============================================================================
// LOGIQUE M√âTIER & BONUS
// ============================================================================

function applyDomainBonus(
  chunks: MatchedChunk[],
  domain: DomainConfig | null
): MatchedChunk[] {
  console.log(`[rag-chat] Applying Domain Bonuses (${domain?.id || 'None'})...`);
  
  return chunks.map(chunk => {
    let newScore = chunk.score;
    
    if (isReferenceDocument(chunk.documentTitle)) newScore += CONFIG.referenceDocBonus;

    if (domain && isDomainDocument(chunk.documentTitle, domain)) {
      newScore += domain.bonus;
    }
    
    return { ...chunk, score: newScore };
  }).sort((a, b) => b.score - a.score);
}

function ensureDomainDocuments(
  chunks: MatchedChunk[],
  allAvailableChunks: MatchedChunk[],
  domain: DomainConfig | null,
  topK: number
): MatchedChunk[] {
  if (!domain) return chunks.slice(0, topK);

  const domainChunks = chunks.filter(c => isDomainDocument(c.documentTitle, domain));
  
  if (domainChunks.length >= domain.minDocs) return chunks.slice(0, topK);

  console.log(`[rag-chat] Rescue: Injecting missing ${domain.id} documents...`);
  
  const existingIds = new Set(chunks.map(c => c.id));
  const missingCount = domain.minDocs - domainChunks.length;
  
  const rescueChunks = allAvailableChunks
    .filter(c => isDomainDocument(c.documentTitle, domain) && !existingIds.has(c.id))
    .sort((a, b) => b.score - a.score)
    .slice(0, missingCount);
    
  const merged = [...chunks, ...rescueChunks].sort((a, b) => b.score - a.score);
  return merged.slice(0, topK);
}

// ============================================================================
// RE-RANKING
// ============================================================================

async function rerankChunksWithLLM(
  query: string,
  chunks: MatchedChunk[],
  topN: number,
  apiKey: string
): Promise<{ chunks: MatchedChunk[]; tokensUsed: number }> {
  if (chunks.length <= 5) return { chunks: chunks.slice(0, topN), tokensUsed: 0 };

  console.log(`[rag-chat] Re-ranking ${chunks.length} chunks...`);

  const excerpts = chunks.slice(0, CONFIG.rerankingChunkCount).map((chunk, index) => ({
    id: index, title: chunk.documentTitle, 
    text: chunk.content.substring(0, CONFIG.rerankingContextLength),
  }));

  const prompt = `√âvalue la pertinence (0-10) pour: "${query}"
  - 10: R√©ponse directe.
  - 5: Pertinent.
  - 0: Hors sujet.
  
  Extraits:
  ${excerpts.map(e => `[${e.id}] (${e.title})\n${e.text}`).join('\n\n')}
  
  JSON: {"scores": [{"id": 0, "score": 8}, ...]}`;

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${apiKey}`, 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: CONFIG.rerankingModel,
        messages: [{ role: 'system', content: 'JSON only.' }, { role: 'user', content: prompt }],
        temperature: 0.1, max_tokens: 800,
      }),
    });

    const data = await response.json();
    const jsonMatch = data.choices[0]?.message?.content.match(/\{[\s\S]*\}/);
    
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0]);
      type RerankScore = { id: number; score: number };

const scoreMap = new Map<number, number>(
  ((parsed.scores as RerankScore[]) || []).map(s => [s.id, s.score])
);

const reranked: MatchedChunk[] = chunks.map((chunk, index) => {
  const llmScore: number = scoreMap.get(index) ?? 5;

  const hybridScore: number =
    (chunk.score * 0.4) + ((llmScore / 10) * 0.6);

  return {
    ...chunk,
    rerankScore: hybridScore,
    llmRawScore: llmScore,
  };
});

      reranked.sort((a, b) => b.rerankScore! - a.rerankScore!);

      const valid = reranked.filter(c => c.llmRawScore! > 0);
      return { chunks: (valid.length >= topN ? valid : reranked).slice(0, topN), tokensUsed: data.usage?.total_tokens || 0 };
    }
  } catch (err) {
    console.warn('[rag-chat] Rerank fail', err);
  }
  return { chunks: chunks.slice(0, topN), tokensUsed: 0 };
}

// ============================================================================
// G√âN√âRATION
// ============================================================================

async function generateResponse(
  query: string,
  chunks: MatchedChunk[],
  mode: ChatMode,
  history: any[],
  domain: DomainConfig | null,
  apiKey: string
): Promise<{ answer: string; tokens: number }> {
  if (chunks.length === 0) return { answer: "Je n'ai pas trouv√© d'information.", tokens: 0 };

  const context = chunks.map((c, i) => `[Source ${i + 1}] ${c.documentTitle}\n${c.content}`).join('\n\n---\n\n');

  let roleDesc = domain ? domain.promptRole : "assistant p√©dagogique expert";
  
  let systemPrompt = `Tu es un ${roleDesc}.
  ${mode === 'corpus_only' ? "Utilise UNIQUEMENT les sources." : "Utilise les sources en priorit√©."}
  R√àGLES:
  1. Cite les sources [Source X].
  2. Structure ta r√©ponse.
  3. ${domain?.id === 'LANGUES' ? "Utilise terminologie CECR." : ""}
  4. ${domain?.id === 'EPS' ? "Utilise terminologie APSA/Champs d'apprentissage." : ""}`;

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: { 'Authorization': `Bearer ${apiKey}`, 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: CONFIG.chatModel,
      messages: [
        { role: 'system', content: systemPrompt },
        ...history,
        { role: 'user', content: `SOURCES:\n${context}\n\nQUESTION: ${query}\n\nR√©ponse:` }
      ],
      temperature: 0.3,
    }),
  });

  const data = await response.json();
  return { answer: data.choices[0]?.message?.content || 'Erreur.', tokens: data.usage?.total_tokens || 0 };
}

// ============================================================================
// HELPER: D√©duction des tokens
// ============================================================================

async function deductTokens(serviceClient: any, userId: string, tokensUsed: number): Promise<void> {
  try {
    const { data } = await serviceClient
      .from('profiles')
      .select('tokens')
      .eq('user_id', userId)
      .single();
    
    if (data) {
      await serviceClient
        .from('profiles')
        .update({ tokens: Math.max(0, data.tokens - tokensUsed) })
        .eq('user_id', userId);
      console.log(`[rag-chat] Deducted ${tokensUsed} tokens from user ${userId}`);
    }
  } catch (err) {
    console.error('[rag-chat] Error deducting tokens:', err);
  }
}

// ============================================================================
// HANDLER PRINCIPAL
// ============================================================================

async function chatHandler(req: Request): Promise<Response> {
  if (req.method === 'OPTIONS') return new Response('ok', { headers: corsHeaders });
  if (req.method !== 'POST') return new Response('Err', { status: 405, headers: corsHeaders });

  try {
    const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY')!;
    const authHeader = req.headers.get('Authorization');
    if (!authHeader) throw new Error('Auth Missing');

    const supabase = await createSupabaseClient(authHeader);
    const serviceClient = await createServiceClient();
    const { data: { user } } = await supabase.auth.getUser();
    if (!user) throw new Error('User Invalid');

    // üÜï Extraction des param√®tres avec les nouveaux switches et filtres
    const { 
      message, 
      mode = 'corpus_plus_ai', 
      searchMode = 'fast', 
      conversationId, 
      documentId,
      usePersonalCorpus = true,
      useProfAssistCorpus = true,
      useAI = false,
      levels,
      subjects,
      documentTypes
    } = await req.json() as ChatRequest;

    // üÜï D√©terminer le mode effectif bas√© sur useAI
    const effectiveMode: ChatMode = useAI ? 'corpus_plus_ai' : 'corpus_only';

    console.log(`[rag-chat] Handling: "${message}" | mode=${effectiveMode} | personal=${usePersonalCorpus} | profassist=${useProfAssistCorpus} | ai=${useAI}`);

    // 1. S√âCURIT√â: Docs autoris√©s avec filtrage switches et m√©tadonn√©es
    const allowedDocsMap = await getAllowedDocuments(
      serviceClient, 
      user.id, 
      documentId,
      usePersonalCorpus,
      useProfAssistCorpus,
      {
        levels,
        subjects,
        documentTypes
      }
    );
    const allowedDocIdsArr = Array.from(allowedDocsMap.keys());
    const allowedDocIdsSet = new Set(allowedDocIdsArr);

    // üÜï Gestion du cas "IA seule" ou "aucun document"
    if (allowedDocIdsArr.length === 0) {
      // Mode IA seule - r√©pondre sans recherche de documents
      if (useAI && !usePersonalCorpus && !useProfAssistCorpus) {
        console.log(`[rag-chat] AI-only mode, no corpus search`);
        
        let convId = conversationId;
        if (!convId) {
          const { data } = await serviceClient.from('rag_conversations').insert({ user_id: user.id }).select('id').single();
          convId = data?.id;
        }
        
        const { data: hist } = await serviceClient.from('rag_messages').select('role, content').eq('conversation_id', convId).order('created_at', { ascending: true }).limit(CONFIG.maxHistoryMessages);
        await serviceClient.from('rag_messages').insert({ conversation_id: convId, role: 'user', content: message });
        
        // G√©n√©rer une r√©ponse IA sans contexte documentaire
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: { 'Authorization': `Bearer ${OPENAI_API_KEY}`, 'Content-Type': 'application/json' },
          body: JSON.stringify({
            model: CONFIG.chatModel,
            messages: [
              { role: 'system', content: 'Tu es un assistant p√©dagogique expert. R√©ponds de mani√®re claire et structur√©e. Indique clairement que ta r√©ponse provient de tes connaissances g√©n√©rales et non de documents sp√©cifiques.' },
              ...(hist || []).map((m: any) => ({ role: m.role, content: m.content })),
              { role: 'user', content: message }
            ],
            temperature: 0.3,
          }),
        });
        
        const data = await response.json();
        const answer = data.choices[0]?.message?.content || 'Erreur lors de la g√©n√©ration.';
        const tokensUsed = data.usage?.total_tokens || 0;
        
        await serviceClient.from('rag_messages').insert({ conversation_id: convId, role: 'assistant', content: answer, sources: [] });
        
        // D√©duire les tokens
        await deductTokens(serviceClient, user.id, tokensUsed);
        
        return new Response(JSON.stringify({
          answer, 
          sources: [], 
          conversationId: convId, 
          tokensUsed, 
          mode: 'corpus_plus_ai',
          searchMode: 'fast'
        }), { headers: { ...corsHeaders, 'Content-Type': 'application/json' } });
      }
      
      // Aucun document et pas d'IA
      return new Response(JSON.stringify({ 
        answer: "Aucun document disponible dans les corpus s√©lectionn√©s (ou via les filtres actifs).", 
        sources: [],
        conversationId: null,
        tokensUsed: 0,
        mode: effectiveMode
      }), { headers: { ...corsHeaders, 'Content-Type': 'application/json' } });
    }

    // 2. D√âTECTION
    const activeDomain = detectDomainIntent(message);
    const isComparative = isComparativeQuestion(message);
    const effectiveSearchMode = (activeDomain || isComparative || searchMode === 'precise') ? 'precise' : 'fast';
    let totalTokens = 0;

    // 3. PR√âPARATION (HyDE / Rewrite)
    let hypothetical = message;
    if (effectiveSearchMode === 'precise') {
      const h = await generateHypotheticalAnswer(message, activeDomain, OPENAI_API_KEY);
      hypothetical = h.hypotheticalAnswer;
      totalTokens += h.tokensUsed;
    }

    let queries = [message];
    if (effectiveSearchMode === 'precise') {
      const rw = await rewriteQueryForSearch(message, activeDomain, OPENAI_API_KEY);
      queries = rw.queries;
      totalTokens += rw.tokensUsed;
    }

    // Embeddings
    const qEmb = await createEmbedding(message, OPENAI_API_KEY);
    const hEmb = effectiveSearchMode === 'precise' ? await createEmbedding(hypothetical, OPENAI_API_KEY) : [];
    totalTokens += Math.ceil((message.length + hypothetical.length) / 4);

    // 4. RECHERCHE UNIFI√âE
    const allChunks: MatchedChunk[] = [];
    const seenIds = new Set<string>();
    const add = (arr: MatchedChunk[]) => arr.forEach(c => { if(!seenIds.has(c.id)) { seenIds.add(c.id); allChunks.push(c); }});

    // A. Recherche Sp√©cifique Domaine
    if (activeDomain) {
      add(await searchSpecificDomainDocuments(serviceClient, allowedDocsMap, activeDomain, message));
    }

    // B. Recherche Mots-cl√©s (Sur variantes)
    for (const q of queries.slice(0, 3)) {
      add(await searchByKeywords(serviceClient, allowedDocIdsArr, allowedDocsMap, extractKeyTerms(q)));
    }

    // C. Vectorielle
    if (hEmb.length > 0) {
      const hydeRes = await searchByVector(serviceClient, user.id, hEmb, CONFIG.defaultTopK, allowedDocIdsSet);
      hydeRes.forEach(c => c.score *= 1.1);
      add(hydeRes);
    }
    add(await searchByVector(serviceClient, user.id, qEmb, CONFIG.defaultTopK, allowedDocIdsSet));

    // 5. CLASSEMENT & LOGIQUE M√âTIER
    let candidates = applyDomainBonus(allChunks, activeDomain);

    if (effectiveSearchMode === 'precise') {
      const rr = await rerankChunksWithLLM(message, candidates, CONFIG.finalChunkCount, OPENAI_API_KEY);
      candidates = rr.chunks;
      totalTokens += rr.tokensUsed;
    } else {
      candidates = candidates.slice(0, CONFIG.finalChunkCount);
    }

    // Sauvetage (Rescue)
    candidates = ensureDomainDocuments(candidates, allChunks, activeDomain, CONFIG.finalChunkCount);
    console.log(`[rag-chat] Final count: ${candidates.length}`);

    // 6. G√âN√âRATION
    let convId = conversationId;
    if (!convId) {
      const { data } = await serviceClient.from('rag_conversations').insert({ user_id: user.id }).select('id').single();
      convId = data?.id;
    }
    const { data: hist } = await serviceClient.from('rag_messages').select('role, content').eq('conversation_id', convId).order('created_at', { ascending: true }).limit(CONFIG.maxHistoryMessages);
    await serviceClient.from('rag_messages').insert({ conversation_id: convId, role: 'user', content: message });

    const { answer, tokens } = await generateResponse(message, candidates, effectiveMode, hist || [], activeDomain, OPENAI_API_KEY);
    totalTokens += tokens;

    const sources = candidates.map(c => ({
      documentId: c.documentId, documentTitle: c.documentTitle, chunkId: c.id, chunkIndex: c.chunkIndex,
      excerpt: c.content.substring(0, CONFIG.excerptLength), score: c.score, scope: c.scope
    }));
    await serviceClient.from('rag_messages').insert({ conversation_id: convId, role: 'assistant', content: answer, sources });
    
    // D√©duire les tokens
    await deductTokens(serviceClient, user.id, totalTokens);

    return new Response(JSON.stringify({
      answer, sources, conversationId: convId, tokensUsed: totalTokens, mode: effectiveMode, searchMode: effectiveSearchMode
    }), { headers: { ...corsHeaders, 'Content-Type': 'application/json' } });

  } catch (e: any) {
    console.error(e);
    return new Response(JSON.stringify({ error: e.message }), { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } });
  }
}

Deno.serve(chatHandler);


