// supabase/functions/rag-chat/index.ts
// Edge Function pour le chat RAG avec:
// - Query Rewriting
// - HyDE (Hypothetical Document Embeddings)
// - Re-ranking LLM
// - text-embedding-3-large (dimensions r√©duites √† 1536)
// - Seuil de similarit√© optimis√©
// - D√©duction des tokens du compte utilisateur

declare const Deno: {
  env: {
    get(key: string): string | undefined;
  };
  serve(handler: (req: Request) => Promise<Response>): void;
};

// ============================================================================
// CONFIGURATION
// ============================================================================

const CONFIG = {
  // Recherche
  defaultTopK: 6,
  maxTopK: 12,
  similarityThreshold: 0.35,
  
  // Mod√®les
  chatModel: 'gpt-4o-mini',
  embeddingModel: 'text-embedding-3-large',
  embeddingDimensions: 1536,  // R√©duit pour compatibilit√© HNSW
  
  // Query Rewriting
  enableQueryRewriting: true,
  queryRewritingModel: 'gpt-4o-mini',
  
  // HyDE (Hypothetical Document Embeddings)
  enableHyDE: true,
  hydeModel: 'gpt-4o-mini',
  
  // Re-ranking
  enableReranking: true,
  rerankingModel: 'gpt-4o-mini',
  rerankingChunkCount: 15,
  finalChunkCount: 8,
  
  // Historique
  maxHistoryMessages: 10,
};

// ============================================================================
// TYPES
// ============================================================================

type ChatMode = 'corpus_only' | 'corpus_plus_ai';

interface ChatRequest {
  message: string;
  mode: ChatMode;
  conversationId?: string;
  documentId?: string;
  topK?: number;
}

interface MatchedChunk {
  id: string;
  documentId: string;
  documentTitle: string;
  chunkIndex: number;
  content: string;
  score: number;
  scope?: 'global' | 'user';
}

interface SourceChunk {
  documentId: string;
  documentTitle: string;
  chunkId: string;
  chunkIndex: number;
  excerpt: string;
  score: number;
  scope?: 'global' | 'user';
}

interface ChatResponse {
  answer: string;
  sources: SourceChunk[];
  conversationId: string;
  tokensUsed: number;
  mode: ChatMode;
}

// ============================================================================
// HELPERS - CORS & AUTH
// ============================================================================

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

async function createSupabaseClient(authHeader: string) {
  const { createClient } = await import('https://esm.sh/@supabase/supabase-js@2');
  const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
  const supabaseKey = Deno.env.get('SUPABASE_ANON_KEY')!;

  return createClient(supabaseUrl, supabaseKey, {
    global: { headers: { Authorization: authHeader } },
  });
}

async function createServiceClient() {
  const { createClient } = await import('https://esm.sh/@supabase/supabase-js@2');
  const supabaseUrl = Deno.env.get('SUPABASE_URL')!;
  const serviceRoleKey = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!;

  return createClient(supabaseUrl, serviceRoleKey);
}

// ============================================================================
// HyDE: HYPOTHETICAL DOCUMENT EMBEDDINGS
// ============================================================================

async function generateHypotheticalAnswer(
  query: string,
  apiKey: string
): Promise<{ hypotheticalAnswer: string; tokensUsed: number }> {
  if (!CONFIG.enableHyDE) {
    return { hypotheticalAnswer: query, tokensUsed: 0 };
  }

  console.log(`[rag-chat] HyDE: Generating hypothetical answer for "${query.substring(0, 50)}..."`);

  const prompt = `Tu es un expert en √©ducation nationale fran√ßaise. G√©n√®re une r√©ponse compl√®te et d√©taill√©e √† la question suivante, comme si tu avais acc√®s aux documents officiels.

IMPORTANT: 
- √âcris une r√©ponse factuelle et structur√©e
- Utilise le vocabulaire officiel de l'√âducation Nationale
- Inclus des termes sp√©cifiques (cycles, comp√©tences, attendus, programmes, etc.)
- La r√©ponse doit faire 150-300 mots

Question: "${query}"

R√©ponse hypoth√©tique:`;

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: CONFIG.hydeModel,
        messages: [
          { 
            role: 'system', 
            content: 'Tu es un assistant expert en programmes scolaires fran√ßais. Tu g√©n√®res des r√©ponses d√©taill√©es et pr√©cises bas√©es sur les textes officiels de l\'√âducation Nationale.' 
          },
          { role: 'user', content: prompt },
        ],
        temperature: 0.3,
        max_tokens: 500,
      }),
    });

    if (!response.ok) {
      console.warn('[rag-chat] HyDE generation failed, using original query');
      return { hypotheticalAnswer: query, tokensUsed: 0 };
    }

    const data = await response.json();
    const hypotheticalAnswer = data.choices[0]?.message?.content || query;
    const tokensUsed = data.usage?.total_tokens || 0;

    console.log(`[rag-chat] HyDE: Generated ${hypotheticalAnswer.length} chars hypothetical answer`);

    return { hypotheticalAnswer, tokensUsed };
  } catch (error) {
    console.warn('[rag-chat] HyDE error:', error);
    return { hypotheticalAnswer: query, tokensUsed: 0 };
  }
}

// ============================================================================
// QUERY REWRITING
// ============================================================================

async function rewriteQueryForSearch(
  query: string,
  apiKey: string
): Promise<{ queries: string[]; tokensUsed: number }> {
  if (!CONFIG.enableQueryRewriting) {
    return { queries: [query], tokensUsed: 0 };
  }

  console.log(`[rag-chat] Query Rewriting: "${query.substring(0, 50)}..."`);

  const prompt = `Tu es un expert en √©ducation nationale fran√ßaise. Ta t√¢che est de reformuler la question suivante pour maximiser les chances de trouver les bons documents p√©dagogiques.

Question originale: "${query}"

G√©n√®re 3-4 reformulations de cette question en:
1. Utilisant les termes officiels de l'√âducation Nationale
2. Ajoutant des synonymes pertinents
3. Pr√©cisant les niveaux scolaires si implicites (maternelle, cycle 1/2/3/4, CP, CE1, CM2, coll√®ge, lyc√©e)
4. Incluant les abr√©viations ET les formes longues (EPS/√©ducation physique, EMC/enseignement moral et civique)

EXEMPLES:
- "grammaire CP" ‚Üí ["grammaire cours pr√©paratoire cycle 2", "√©tude de la langue CP CE1 CE2", "fran√ßais grammaire √©l√©mentaire cycle 2"]
- "sport maternelle" ‚Üí ["activit√© physique maternelle cycle 1", "EPS √©ducation physique maternelle", "agir s'exprimer comprendre activit√© physique petite section"]

R√©ponds UNIQUEMENT avec un JSON valide contenant un tableau "queries" (4 √©l√©ments max):
{"queries": ["reformulation 1", "reformulation 2", "reformulation 3"]}`;

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: CONFIG.queryRewritingModel,
        messages: [
          { role: 'system', content: 'Tu es un assistant qui g√©n√®re des reformulations de questions. R√©ponds uniquement en JSON valide.' },
          { role: 'user', content: prompt },
        ],
        temperature: 0.3,
        max_tokens: 300,
      }),
    });

    if (!response.ok) {
      console.warn('[rag-chat] Query Rewriting failed, using original query');
      return { queries: [query], tokensUsed: 0 };
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content || '';
    const tokensUsed = data.usage?.total_tokens || 0;

    const jsonMatch = content.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0]);
      const queries = [query, ...(parsed.queries || [])];
      console.log(`[rag-chat] Query variations: ${queries.length}`);
      return { queries: queries.slice(0, 5), tokensUsed };
    }

    return { queries: [query], tokensUsed };
  } catch (error) {
    console.warn('[rag-chat] Query Rewriting error:', error);
    return { queries: [query], tokensUsed: 0 };
  }
}

// ============================================================================
// RE-RANKING
// ============================================================================

async function rerankChunksWithLLM(
  query: string,
  chunks: MatchedChunk[],
  topN: number,
  apiKey: string
): Promise<{ chunks: MatchedChunk[]; tokensUsed: number }> {
  if (!CONFIG.enableReranking || chunks.length === 0) {
    return { chunks: chunks.slice(0, topN), tokensUsed: 0 };
  }

  console.log(`[rag-chat] Re-ranking ${chunks.length} chunks...`);

  const excerpts = chunks.map((chunk, index) => ({
    id: index,
    text: chunk.content.substring(0, 800) + (chunk.content.length > 800 ? '...' : ''),
  }));

  const prompt = `Tu es un expert en pertinence documentaire pour l'√©ducation nationale fran√ßaise. √âvalue la pertinence de chaque extrait par rapport √† la question.

Question: "${query}"

Extraits √† √©valuer:
${excerpts.map(e => `[${e.id}] ${e.text}`).join('\n\n')}

Pour chaque extrait, attribue un score de 0 √† 10:
- 10 = R√©pond DIRECTEMENT et COMPL√àTEMENT √† la question avec des informations sp√©cifiques
- 7-9 = Contient la r√©ponse avec des d√©tails pertinents
- 4-6 = Partiellement pertinent, informations connexes utiles
- 1-3 = Marginalement li√© au sujet
- 0 = Hors sujet ou trop g√©n√©rique

IMPORTANT: 
- Privil√©gie les extraits avec des INFORMATIONS SP√âCIFIQUES et CONCR√àTES
- P√©nalise les introductions g√©n√©rales sans contenu actionnable
- Favorise les extraits mentionnant des comp√©tences, attendus, ou objectifs pr√©cis

R√©ponds UNIQUEMENT avec un JSON valide:
{"scores": [{"id": 0, "score": 8}, {"id": 1, "score": 3}, ...]}`;

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: CONFIG.rerankingModel,
        messages: [
          { role: 'system', content: 'Tu es un √©valuateur de pertinence documentaire expert en √©ducation fran√ßaise. R√©ponds uniquement en JSON valide.' },
          { role: 'user', content: prompt },
        ],
        temperature: 0.1,
        max_tokens: 600,
      }),
    });

    if (!response.ok) {
      console.warn('[rag-chat] Re-ranking failed, using vector scores');
      return { chunks: chunks.slice(0, topN), tokensUsed: 0 };
    }

    const data = await response.json();
    const content = data.choices[0]?.message?.content || '';
    const tokensUsed = data.usage?.total_tokens || 0;

    const jsonMatch = content.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0]);
      const scores = parsed.scores || [];

      const scoreMap = new Map<number, number>();
      for (const s of scores) {
        scoreMap.set(s.id, s.score);
      }

      const rerankedChunks = chunks
        .map((chunk, index) => ({
          ...chunk,
          rerankScore: scoreMap.get(index) ?? 0,
        }))
        .sort((a, b) => b.rerankScore - a.rerankScore)
        .slice(0, topN);

      console.log(`[rag-chat] Re-ranked: top scores = ${rerankedChunks.map(c => c.rerankScore).join(', ')}`);

      return { chunks: rerankedChunks, tokensUsed };
    }

    return { chunks: chunks.slice(0, topN), tokensUsed };
  } catch (error) {
    console.warn('[rag-chat] Re-ranking error:', error);
    return { chunks: chunks.slice(0, topN), tokensUsed: 0 };
  }
}

// ============================================================================
// EXTRACTION DE TERMES-CL√âS
// ============================================================================

function extractKeyTerms(query: string): string[] {
  const lowerQuery = query.toLowerCase();
  const terms: string[] = [];

  const levelMappings: Record<string, string[]> = {
    'maternelle': ['maternelle', 'cycle 1', 'petite section', 'moyenne section', 'grande section', 'PS', 'MS', 'GS'],
    'cycle 1': ['maternelle', 'cycle 1', 'petite section', 'moyenne section', 'grande section'],
    'cp': ['CP', 'cours pr√©paratoire', 'cycle 2'],
    'ce1': ['CE1', 'cours √©l√©mentaire 1', 'cycle 2'],
    'ce2': ['CE2', 'cours √©l√©mentaire 2', 'cycle 2'],
    'cycle 2': ['cycle 2', 'CP', 'CE1', 'CE2', 'cours pr√©paratoire', 'cours √©l√©mentaire'],
    'cm1': ['CM1', 'cours moyen 1', 'cycle 3'],
    'cm2': ['CM2', 'cours moyen 2', 'cycle 3'],
    '6e': ['6e', '6√®me', 'sixi√®me', 'cycle 3'],
    'sixi√®me': ['6e', '6√®me', 'sixi√®me', 'cycle 3'],
    'cycle 3': ['cycle 3', 'CM1', 'CM2', '6e', 'sixi√®me'],
    '5e': ['5e', '5√®me', 'cinqui√®me', 'cycle 4', 'coll√®ge'],
    '4e': ['4e', '4√®me', 'quatri√®me', 'cycle 4', 'coll√®ge'],
    '3e': ['3e', '3√®me', 'troisi√®me', 'cycle 4', 'coll√®ge'],
    'cycle 4': ['cycle 4', '5e', '4e', '3e', 'coll√®ge'],
    'coll√®ge': ['coll√®ge', 'cycle 3', 'cycle 4', '6e', '5e', '4e', '3e'],
    'lyc√©e': ['lyc√©e', 'seconde', 'premi√®re', 'terminale', '2nde'],
    'seconde': ['seconde', '2nde', 'lyc√©e'],
    'premi√®re': ['premi√®re', '1√®re', 'lyc√©e'],
    'terminale': ['terminale', 'Tle', 'lyc√©e'],
  };

  const subjectMappings: Record<string, string[]> = {
    'eps': ['EPS', '√©ducation physique', 'sport', 'activit√© physique', 'champ d\'apprentissage'],
    '√©ducation physique': ['EPS', '√©ducation physique', 'sport', 'activit√© physique'],
    'sport': ['EPS', 'sport', 'activit√© physique', '√©ducation physique'],
    'fran√ßais': ['fran√ßais', 'lecture', '√©criture', 'grammaire', 'orthographe', 'vocabulaire', '√©tude de la langue'],
    'grammaire': ['grammaire', 'fran√ßais', '√©tude de la langue', 'syntaxe', 'conjugaison'],
    'lecture': ['lecture', 'fran√ßais', 'compr√©hension', 'lire'],
    '√©criture': ['√©criture', 'fran√ßais', 'production d\'√©crit', 'r√©daction'],
    'orthographe': ['orthographe', 'fran√ßais', 'dict√©e'],
    'math': ['math√©matiques', 'maths', 'calcul', 'g√©om√©trie', 'num√©ration'],
    'maths': ['math√©matiques', 'maths', 'calcul', 'g√©om√©trie', 'num√©ration'],
    'math√©matiques': ['math√©matiques', 'maths', 'calcul', 'g√©om√©trie', 'num√©ration', 'nombres'],
    'calcul': ['calcul', 'math√©matiques', 'op√©rations', 'nombres'],
    'g√©om√©trie': ['g√©om√©trie', 'math√©matiques', 'espace', 'figures'],
    'sciences': ['sciences', 'SVT', 'physique', 'chimie', 'biologie', 'technologie'],
    'svt': ['SVT', 'sciences de la vie', 'biologie', 'sciences'],
    'histoire': ['histoire', 'histoire-g√©ographie', 'pass√©', 'civilisation'],
    'g√©ographie': ['g√©ographie', 'histoire-g√©ographie', 'territoire', 'espace'],
    'emc': ['EMC', 'enseignement moral et civique', 'citoyennet√©', '√©ducation civique'],
    'anglais': ['anglais', 'langue vivante', 'LV1', 'English'],
    'arts plastiques': ['arts plastiques', 'art', 'dessin', 'cr√©ation artistique'],
    'musique': ['musique', '√©ducation musicale', 'chant'],
  };

  for (const [key, values] of Object.entries(levelMappings)) {
    if (lowerQuery.includes(key)) {
      terms.push(...values);
    }
  }

  for (const [key, values] of Object.entries(subjectMappings)) {
    if (lowerQuery.includes(key)) {
      terms.push(...values);
    }
  }

  return [...new Set(terms)];
}

// ============================================================================
// RECHERCHE HYBRIDE
// ============================================================================

async function searchByDocumentTitle(
  supabase: any,
  userId: string,
  searchTerms: string[],
  limit: number = 10
): Promise<MatchedChunk[]> {
  if (searchTerms.length === 0) return [];

  const chunkScores = new Map<string, { chunk: MatchedChunk; score: number; matchedTerms: string[] }>();

  const priorityTerms = searchTerms.filter(t =>
    /cycle|maternelle|cp|ce|cm|eps|fran√ßais|math|grammaire/i.test(t)
  );

  const termsToSearch = priorityTerms.length > 0 ? priorityTerms : searchTerms.slice(0, 5);

  for (const term of termsToSearch) {
    try {
      const { data: docs } = await supabase
        .from('rag_documents')
        .select('id, title, scope')
        .or(`scope.eq.global,user_id.eq.${userId}`)
        .eq('status', 'ready')
        .ilike('title', `%${term}%`)
        .limit(3);

      if (!docs || docs.length === 0) continue;

      for (const doc of docs) {
        const { data: chunks } = await supabase
          .from('rag_chunks')
          .select('id, document_id, chunk_index, content')
          .eq('document_id', doc.id)
          .ilike('content', `%${term}%`)
          .order('chunk_index', { ascending: true })
          .limit(5);

        if (!chunks) continue;

        for (const chunk of chunks) {
          const key = chunk.id;
          const existing = chunkScores.get(key);

          if (existing) {
            existing.score += 1;
            existing.matchedTerms.push(term);
          } else {
            chunkScores.set(key, {
              chunk: {
                id: chunk.id,
                documentId: doc.id,
                documentTitle: doc.title,
                chunkIndex: chunk.chunk_index,
                content: chunk.content,
                score: 0.9,
                scope: doc.scope,
              },
              score: 1,
              matchedTerms: [term],
            });
          }
        }
      }
    } catch (err) {
      console.warn(`[rag-chat] Erreur recherche titre pour "${term}":`, err);
    }
  }

  const sortedChunks = Array.from(chunkScores.values())
    .sort((a, b) => {
      if (b.score !== a.score) return b.score - a.score;
      return a.chunk.chunkIndex - b.chunk.chunkIndex;
    })
    .slice(0, limit)
    .map(item => item.chunk);

  console.log(`[rag-chat] Title search: ${sortedChunks.length} chunks from ${chunkScores.size} unique`);

  return sortedChunks;
}

async function searchByKeywords(
  supabase: any,
  userId: string,
  keywords: string[],
  limit: number = 10
): Promise<MatchedChunk[]> {
  if (keywords.length === 0) return [];

  const chunkScores = new Map<string, { chunk: MatchedChunk; score: number }>();

  for (const keyword of keywords.slice(0, 5)) {
    try {
      const { data: chunks } = await supabase
        .from('rag_chunks')
        .select(`
          id,
          document_id,
          chunk_index,
          content,
          rag_documents!inner (
            id,
            title,
            scope,
            user_id
          )
        `)
        .or(`rag_documents.scope.eq.global,rag_documents.user_id.eq.${userId}`)
        .ilike('content', `%${keyword}%`)
        .limit(5);

      if (!chunks) continue;

      for (const chunk of chunks) {
        const doc = chunk.rag_documents;
        const key = chunk.id;

        const existing = chunkScores.get(key);
        if (existing) {
          existing.score += 1;
        } else {
          chunkScores.set(key, {
            chunk: {
              id: chunk.id,
              documentId: doc.id,
              documentTitle: doc.title,
              chunkIndex: chunk.chunk_index,
              content: chunk.content,
              score: 0.85,
              scope: doc.scope,
            },
            score: 1,
          });
        }
      }
    } catch (err) {
      console.warn(`[rag-chat] Erreur keyword search pour "${keyword}":`, err);
    }
  }

  return Array.from(chunkScores.values())
    .sort((a, b) => b.score - a.score)
    .slice(0, limit)
    .map(item => item.chunk);
}

async function searchByVector(
  supabase: any,
  userId: string,
  embedding: number[],
  topK: number,
  documentId?: string
): Promise<MatchedChunk[]> {
  try {
    const { data, error } = await supabase.rpc('match_rag_chunks', {
      query_embedding: JSON.stringify(embedding),
      match_threshold: CONFIG.similarityThreshold,
      match_count: topK,
      p_user_id: userId,
      p_document_id: documentId || null,
    });

    if (error) {
      console.error('[rag-chat] Vector search error:', error);
      return [];
    }

    return (data || []).map((item: any) => ({
      id: item.id,
      documentId: item.document_id,
      documentTitle: item.document_title,
      chunkIndex: item.chunk_index,
      content: item.content,
      score: item.similarity,
      scope: item.scope,
    }));
  } catch (err) {
    console.error('[rag-chat] Vector search exception:', err);
    return [];
  }
}

async function searchChunksWithHyDE(
  supabase: any,
  userId: string,
  originalQuery: string,
  queryVariations: string[],
  hydeEmbedding: number[],
  queryEmbedding: number[],
  topK: number,
  documentId?: string
): Promise<MatchedChunk[]> {
  const allChunks: MatchedChunk[] = [];
  const seenIds = new Set<string>();

  // 1. Recherche par mots-cl√©s dans les titres et contenus
  for (const query of queryVariations) {
    const terms = extractKeyTerms(query);

    if (terms.length > 0) {
      const titleChunks = await searchByDocumentTitle(supabase, userId, terms, 5);
      for (const chunk of titleChunks) {
        if (!seenIds.has(chunk.id)) {
          seenIds.add(chunk.id);
          allChunks.push(chunk);
        }
      }

      const keywordChunks = await searchByKeywords(supabase, userId, terms, 5);
      for (const chunk of keywordChunks) {
        if (!seenIds.has(chunk.id)) {
          seenIds.add(chunk.id);
          allChunks.push(chunk);
        }
      }
    }
  }

  // 2. Recherche vectorielle avec HyDE (r√©ponse hypoth√©tique)
  if (CONFIG.enableHyDE && hydeEmbedding.length > 0) {
    console.log('[rag-chat] HyDE vector search...');
    const hydeChunks = await searchByVector(supabase, userId, hydeEmbedding, topK * 2, documentId);
    for (const chunk of hydeChunks) {
      if (!seenIds.has(chunk.id)) {
        seenIds.add(chunk.id);
        chunk.score = Math.min(1, chunk.score * 1.1);
        allChunks.push(chunk);
      }
    }
  }

  // 3. Recherche vectorielle classique (question originale)
  console.log('[rag-chat] Original query vector search...');
  const vectorChunks = await searchByVector(supabase, userId, queryEmbedding, topK * 2, documentId);
  for (const chunk of vectorChunks) {
    if (!seenIds.has(chunk.id)) {
      seenIds.add(chunk.id);
      allChunks.push(chunk);
    }
  }

  console.log(`[rag-chat] Combined search: ${allChunks.length} unique chunks`);

  return allChunks.sort((a, b) => b.score - a.score);
}

// ============================================================================
// EMBEDDINGS
// ============================================================================

async function createEmbedding(text: string, apiKey: string): Promise<number[]> {
  const response = await fetch('https://api.openai.com/v1/embeddings', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: CONFIG.embeddingModel,
      input: text,
      dimensions: CONFIG.embeddingDimensions,  // R√©duit √† 1536 pour compatibilit√© HNSW
    }),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`Erreur embedding: ${error}`);
  }

  const data = await response.json();
  return data.data[0].embedding;
}

// ============================================================================
// G√âN√âRATION DE R√âPONSE
// ============================================================================

async function generateResponse(
  query: string,
  chunks: MatchedChunk[],
  mode: ChatMode,
  history: Array<{ role: string; content: string }>,
  apiKey: string
): Promise<{ answer: string; tokensUsed: number }> {
  const context = chunks
    .map((chunk, i) => `[Source ${i + 1}: ${chunk.documentTitle}]\n${chunk.content}`)
    .join('\n\n---\n\n');

  let systemPrompt: string;
  let userPrompt: string;

  if (mode === 'corpus_only') {
    systemPrompt = `Tu es un assistant p√©dagogique pour les enseignants fran√ßais. Tu r√©ponds UNIQUEMENT √† partir des documents fournis.

R√àGLES STRICTES:
- R√©ponds UNIQUEMENT avec les informations des sources fournies
- Si l'information n'est pas dans les sources, dis clairement "Cette information n'est pas pr√©sente dans les documents disponibles."
- Cite TOUJOURS les sources utilis√©es en mentionnant leur titre entre crochets [Titre du document]
- Privil√©gie les citations directes quand c'est pertinent
- Si les sources ne permettent qu'une r√©ponse partielle, indique-le clairement
- Sois pr√©cis, factuel et structur√©
- Utilise des listes √† puces pour les √©num√©rations

IMPORTANT: Ne jamais inventer ou extrapoler des informations qui ne sont pas explicitement dans les sources.`;

    userPrompt = `Documents disponibles:\n${context}\n\n---\n\nQuestion: ${query}\n\nR√©ponds en citant les sources entre crochets.`;
  } else {
    systemPrompt = `Tu es un assistant p√©dagogique expert pour les enseignants fran√ßais. Tu utilises les documents fournis comme base principale, compl√©t√©s par tes connaissances.

R√àGLES:
- Commence TOUJOURS par les informations des sources fournies
- Cite les sources utilis√©es entre crochets [Titre du document]
- Tu peux compl√©ter avec tes connaissances p√©dagogiques si pertinent
- Distingue clairement ce qui vient des sources (prioritaire) et ce qui vient de tes connaissances (compl√©mentaire)
- Sois pr√©cis, pratique et adapt√© au contexte √©ducatif fran√ßais
- Structure ta r√©ponse avec des titres si n√©cessaire`;

    userPrompt = `Documents de r√©f√©rence:\n${context}\n\n---\n\nQuestion: ${query}\n\nR√©ponds en citant d'abord les sources, puis compl√®te si n√©cessaire.`;
  }

  const messages = [
    { role: 'system', content: systemPrompt },
    ...history.slice(-CONFIG.maxHistoryMessages),
    { role: 'user', content: userPrompt },
  ];

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: CONFIG.chatModel,
      messages,
      temperature: 0.3,
      max_tokens: 1500,
    }),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`Erreur g√©n√©ration: ${error}`);
  }

  const data = await response.json();
  return {
    answer: data.choices[0]?.message?.content || 'D√©sol√©, je n\'ai pas pu g√©n√©rer de r√©ponse.',
    tokensUsed: data.usage?.total_tokens || 0,
  };
}

// ============================================================================
// GESTION DES CONVERSATIONS
// ============================================================================

async function getOrCreateConversation(
  supabase: any,
  userId: string,
  conversationId?: string
): Promise<string> {
  if (conversationId) {
    const { data } = await supabase
      .from('rag_conversations')
      .select('id')
      .eq('id', conversationId)
      .eq('user_id', userId)
      .single();

    if (data) return conversationId;
  }

  const { data, error } = await supabase
    .from('rag_conversations')
    .insert({ user_id: userId })
    .select('id')
    .single();

  if (error) throw new Error('Impossible de cr√©er la conversation');
  return data.id;
}

async function getConversationHistory(
  supabase: any,
  conversationId: string
): Promise<Array<{ role: string; content: string }>> {
  const { data } = await supabase
    .from('rag_messages')
    .select('role, content')
    .eq('conversation_id', conversationId)
    .order('created_at', { ascending: true })
    .limit(CONFIG.maxHistoryMessages * 2);

  return data || [];
}

async function saveMessage(
  supabase: any,
  conversationId: string,
  role: 'user' | 'assistant',
  content: string,
  sources?: SourceChunk[]
): Promise<void> {
  await supabase.from('rag_messages').insert({
    conversation_id: conversationId,
    role,
    content,
    sources: sources ? JSON.stringify(sources) : null,
  });
}

// ============================================================================
// GESTION DES TOKENS DU COMPTE UTILISATEUR
// ============================================================================

/**
 * V√©rifie que l'utilisateur a assez de tokens et les d√©duit de son compte
 */
async function checkAndDeductUserTokens(
  supabase: any,
  userId: string,
  tokensToDeduct: number
): Promise<{ success: boolean; newBalance: number; error?: string }> {
  try {
    // 1. R√©cup√©rer le solde actuel
    const { data: profile, error: fetchError } = await supabase
      .from('profiles')
      .select('tokens')
      .eq('user_id', userId)
      .single();

    if (fetchError || !profile) {
      console.error('[rag-chat] Error fetching user profile:', fetchError);
      return { success: false, newBalance: 0, error: 'Profil utilisateur non trouv√©' };
    }

    const currentBalance = profile.tokens || 0;

    // 2. V√©rifier que l'utilisateur a assez de tokens
    if (currentBalance < tokensToDeduct) {
      console.warn(`[rag-chat] Insufficient tokens: ${currentBalance} < ${tokensToDeduct}`);
      return { 
        success: false, 
        newBalance: currentBalance, 
        error: `Tokens insuffisants (${currentBalance} disponibles, ${tokensToDeduct} requis)` 
      };
    }

    // 3. D√©duire les tokens
    const newBalance = currentBalance - tokensToDeduct;
    
    const { error: updateError } = await supabase
      .from('profiles')
      .update({ tokens: newBalance })
      .eq('user_id', userId);

    if (updateError) {
      console.error('[rag-chat] Error updating tokens:', updateError);
      return { success: false, newBalance: currentBalance, error: 'Erreur lors de la mise √† jour des tokens' };
    }

    console.log(`[rag-chat] Tokens deducted: ${currentBalance} - ${tokensToDeduct} = ${newBalance}`);
    
    return { success: true, newBalance };
  } catch (err: any) {
    console.error('[rag-chat] Token deduction error:', err);
    return { success: false, newBalance: 0, error: err.message };
  }
}

// ============================================================================
// HANDLER PRINCIPAL
// ============================================================================

async function chatHandler(req: Request): Promise<Response> {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders });
  }

  if (req.method !== 'POST') {
    return new Response(JSON.stringify({ error: 'M√©thode non autoris√©e' }), {
      status: 405,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }

  try {
    const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY');
    if (!OPENAI_API_KEY) {
      throw new Error('OPENAI_API_KEY non configur√©e');
    }

    const authHeader = req.headers.get('Authorization');
    if (!authHeader) {
      return new Response(JSON.stringify({ error: 'Non authentifi√©' }), {
        status: 401,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    const supabase = await createSupabaseClient(authHeader);
    const serviceClient = await createServiceClient();

    const { data: { user }, error: userError } = await supabase.auth.getUser();
    if (userError || !user) {
      return new Response(JSON.stringify({ error: 'Session invalide' }), {
        status: 401,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    const {
      message,
      mode = 'corpus_plus_ai',
      conversationId,
      documentId,
      topK = CONFIG.defaultTopK,
    }: ChatRequest = await req.json();

    if (!message || message.trim().length === 0) {
      return new Response(JSON.stringify({ error: 'Message requis' }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    console.log(`[rag-chat] ========================================`);
    console.log(`[rag-chat] Query: "${message}" (mode: ${mode})`);
    console.log(`[rag-chat] Embedding model: ${CONFIG.embeddingModel} (${CONFIG.embeddingDimensions} dims)`);
    console.log(`[rag-chat] HyDE enabled: ${CONFIG.enableHyDE}`);
    console.log(`[rag-chat] Similarity threshold: ${CONFIG.similarityThreshold}`);

    let totalTokensUsed = 0;

    // PHASE HyDE: G√©n√©rer une r√©ponse hypoth√©tique
    const { hypotheticalAnswer, tokensUsed: hydeTokens } = await generateHypotheticalAnswer(
      message,
      OPENAI_API_KEY
    );
    totalTokensUsed += hydeTokens;
    console.log(`[rag-chat] HyDE: ${hydeTokens} tokens`);

    // PHASE Query Rewriting
    const { queries: queryVariations, tokensUsed: rewriteTokens } = await rewriteQueryForSearch(
      message,
      OPENAI_API_KEY
    );
    totalTokensUsed += rewriteTokens;
    console.log(`[rag-chat] Query Rewriting: ${rewriteTokens} tokens, ${queryVariations.length} variations`);

    // Cr√©er les embeddings (question originale + r√©ponse hypoth√©tique)
    console.log(`[rag-chat] Creating embeddings with ${CONFIG.embeddingModel}...`);
    
    const [queryEmbedding, hydeEmbedding] = await Promise.all([
      createEmbedding(message, OPENAI_API_KEY),
      CONFIG.enableHyDE 
        ? createEmbedding(hypotheticalAnswer, OPENAI_API_KEY)
        : Promise.resolve([]),
    ]);
    
    // Estimation tokens embeddings
    totalTokensUsed += Math.ceil(message.length / 4);
    if (CONFIG.enableHyDE) {
      totalTokensUsed += Math.ceil(hypotheticalAnswer.length / 4);
    }

    // Recherche hybride avec HyDE
    const chunksToRerank = CONFIG.enableReranking ? CONFIG.rerankingChunkCount : topK;
    const retrievedChunks = await searchChunksWithHyDE(
      serviceClient,
      user.id,
      message,
      queryVariations,
      hydeEmbedding,
      queryEmbedding,
      chunksToRerank,
      documentId
    );

    console.log(`[rag-chat] Retrieved ${retrievedChunks.length} chunks for re-ranking`);

    // PHASE Re-ranking
    const { chunks: finalChunks, tokensUsed: rerankTokens } = await rerankChunksWithLLM(
      message,
      retrievedChunks,
      CONFIG.enableReranking ? CONFIG.finalChunkCount : topK,
      OPENAI_API_KEY
    );
    totalTokensUsed += rerankTokens;
    console.log(`[rag-chat] Re-ranking: ${rerankTokens} tokens, ${finalChunks.length} final chunks`);

    // Conversation
    const convId = await getOrCreateConversation(serviceClient, user.id, conversationId);
    const history = await getConversationHistory(serviceClient, convId);

    await saveMessage(serviceClient, convId, 'user', message);

    // G√©n√©ration
    const { answer, tokensUsed: genTokens } = await generateResponse(
      message,
      finalChunks,
      mode,
      history,
      OPENAI_API_KEY
    );
    totalTokensUsed += genTokens;
    console.log(`[rag-chat] Generation: ${genTokens} tokens`);

    // Sources
    const sources: SourceChunk[] = finalChunks.map(chunk => ({
      documentId: chunk.documentId,
      documentTitle: chunk.documentTitle,
      chunkId: chunk.id,
      chunkIndex: chunk.chunkIndex,
      excerpt: chunk.content.substring(0, 300) + (chunk.content.length > 300 ? '...' : ''),
      score: chunk.score,
      scope: chunk.scope,
    }));

    await saveMessage(serviceClient, convId, 'assistant', answer, sources);

    // üîÑ D√âDUIRE LES TOKENS DU COMPTE UTILISATEUR
    console.log(`[rag-chat] Total tokens to deduct: ${totalTokensUsed}`);
    
    const tokenResult = await checkAndDeductUserTokens(serviceClient, user.id, totalTokensUsed);
    
    if (!tokenResult.success) {
      // Si pas assez de tokens, on renvoie quand m√™me la r√©ponse mais avec un warning
      console.warn(`[rag-chat] Token deduction failed: ${tokenResult.error}`);
    } else {
      console.log(`[rag-chat] New token balance: ${tokenResult.newBalance}`);
    }

    console.log(`[rag-chat] ========================================`);

    const response: ChatResponse = {
      answer,
      sources,
      conversationId: convId,
      tokensUsed: totalTokensUsed,
      mode,
    };

    return new Response(JSON.stringify(response), {
      status: 200,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error: any) {
    console.error('[rag-chat] Error:', error);

    const status = error.message?.includes('Tokens insuffisants') ? 402 : 500;

    return new Response(JSON.stringify({
      error: error.message || 'Erreur lors du traitement de la requ√™te',
    }), {
      status,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
}

Deno.serve(chatHandler);